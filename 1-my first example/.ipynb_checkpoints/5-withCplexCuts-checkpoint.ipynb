{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from math import floor, fabs\n",
    "from cplex.callbacks import UserCutCallback\n",
    "import cplex  as CPX\n",
    "import cplex.callbacks as CPX_CB\n",
    "import sys\n",
    "\n",
    "def SecModelParameter ( VarsValue, m, n, my_rhs, my_coef, BranchedVariables):\n",
    "#     print 'BranchedVariables',BranchedVariables\n",
    "    unbranched=list()\n",
    "    c=[]\n",
    "    d=(np.zeros(((2 * m) + (4 * n), 2*n)))\n",
    "    halatest=[]\n",
    "    a=[]\n",
    "    newrow=[]\n",
    "    zer=(np.zeros(((2 * m) + (4 * n), 2*n)))\n",
    "    for i in range (n):\n",
    "        if i not in (BranchedVariables):\n",
    "            unbranched.append(i)\n",
    "    NodeNum=n-len(unbranched)\n",
    "    \n",
    "    \n",
    "    for i in unbranched:   \n",
    "        for h in range (m):\n",
    "            c.append(0)\n",
    "        for h in range (m):\n",
    "            lin=0            \n",
    "            for j in range (n):\n",
    "#                 print 'i', i, 'h', h,'j',j\n",
    "#                 print 'j1',j\n",
    "                if j in (BranchedVariables):\n",
    "#                     print 'j2',j\n",
    "                    sv = VarsValue[BranchedVariables.index(j)]\n",
    "#                     print 'sv', sv\n",
    "                    lin =lin+ (sv * my_coef[h][j]) \n",
    "#                     print 'lin', lin\n",
    "#                 print 'sv'\n",
    "            lin=lin- my_rhs[h]\n",
    "            c.append(lin)                \n",
    "        for h in range (n):\n",
    "            c.append(0)\n",
    "        for h in range (n):\n",
    "            c.append(0)\n",
    "\n",
    "        for jj in range (n):\n",
    "            lin2=-1\n",
    "            if jj in (BranchedVariables):\n",
    "                sv = VarsValue[BranchedVariables.index(jj)]\n",
    "                lin2 =lin2+ sv\n",
    "            c.append(lin2)\n",
    "            \n",
    "        for jj in range (n):\n",
    "            lin2=0\n",
    "            if jj in (BranchedVariables):\n",
    "                lin2 =-1*VarsValue[BranchedVariables.index(jj)]\n",
    "            c.append(lin2)\n",
    "\n",
    "              \n",
    "    k=NodeNum-1 \n",
    "\n",
    "    for i in unbranched: \n",
    "        k=k+1\n",
    "        for t in range(m):              \n",
    "            for j in range(n):    \n",
    "                d[(k-NodeNum)*(2*m+4*n)+t][j+n]=my_coef[t][j] \n",
    "                \n",
    "        for t in range(m):  \n",
    "            d[(k-NodeNum)*(2*m+4*n)+t][n+i]=d[(k-NodeNum)*(2*m+4*n)+t][n+i]-my_rhs[t]   \n",
    "                \n",
    "        for t in range(m):  \n",
    "            for kk in unbranched:\n",
    "                d[(k-NodeNum)*(2*m+4*n)+t+m][kk]=my_coef[t][kk] \n",
    "                \n",
    "\n",
    "        for t in range(m):  \n",
    "            for j in range(n):\n",
    "                d[(k-NodeNum)*(2*m+4*n)+t+m][j+n]=-1*my_coef[t][j] \n",
    "                 \n",
    "        for t in range(m):  \n",
    "            d[(k-NodeNum)*(2*m+4*n)+t+m][n+i]=d[(k-NodeNum)*(2*m+4*n)+t+m][n+i]+my_rhs[t] \n",
    "                \n",
    "        for t in range(n):              \n",
    "            d[(k-NodeNum)*(2*m+4*n)+t+2*m][i]=-1 \n",
    "            \n",
    "        for t in range(n):  \n",
    "            \n",
    "            d[(k-NodeNum)*(2*m+4*n)+2*m+t][n+t]=1 \n",
    "        \n",
    "            \n",
    "        for t in range(n):  \n",
    "            \n",
    "            d[(k-NodeNum)*(2*m+4*n)+2*m+n+t][n+t]=-1 \n",
    "        \n",
    "        for mm in unbranched: \n",
    "             \n",
    "            d[(k-NodeNum)*(2*m+4*n)+2*m+2*n+mm][mm]=1  \n",
    "            \n",
    "        for t in range(n):  \n",
    "            \n",
    "            d[(k-NodeNum)*(2*m+4*n)+t+2*n+2*m][i]=d[(k-NodeNum)*(2*m+4*n)+t+2*n+2*m][i]+1            \n",
    "            \n",
    "\n",
    "        for t in range(n):  \n",
    "            \n",
    "            d[(k-NodeNum)*(2*m+4*n)+2*m+2*n+t][n+t]=-1 \n",
    "\n",
    "        for t in unbranched:  \n",
    "            d[(k-NodeNum)*(2*m+4*n)+2*m+3*n+t][t]=-1  \n",
    "               \n",
    "        \n",
    "        for t in range(n):  \n",
    "            \n",
    "            d[(k-NodeNum)*(2*m+4*n)+2*m+3*n+t][n+t]=1 \n",
    "            \n",
    "        d=np.vstack([d, zer])                          \n",
    "            \n",
    "    d = np.delete(d, slice(((n - NodeNum)*((2 * m) + (4 * n))),((n-NodeNum+1)*((2 * m) + (4 * n)))), axis=0)\n",
    "#     print 'c',c\n",
    "#     print 'unbranched',unbranched\n",
    "    return c, d,unbranched\n",
    "#     print c, d,unbranched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SecondModel (cc,dd,NotBranched):\n",
    "#     print 'cc,dd,NotBranched',cc,dd,NotBranched\n",
    "    numrows = len(dd)    # 3 rows in your example\n",
    "    numcols = len(dd[0])\n",
    "    VarNum=numcols/2\n",
    "    ConstNum=numrows/len(NotBranched)\n",
    "    my_obj=[]\n",
    "    my_ub=[]\n",
    "    my_lb=[]\n",
    "    my_colnames=[]\n",
    "    my_rownames=[\"c1\"]\n",
    "    my_coef=[] \n",
    "    my_row=[]\n",
    "    my_rhs=[]\n",
    "    my_sense=\"\"\n",
    "    my_Nmah=list()\n",
    "    \n",
    "    for i in range(numrows):\n",
    "        my_obj=cc\n",
    "        my_ub.append(1)\n",
    "        my_lb.append(0)\n",
    "        my_colnames.append(\"y\"+str(i))\n",
    "\n",
    "    sumarray=[]     \n",
    "    NotBranched.sort()    \n",
    "#     sumshode=list()\n",
    "    for t in range (VarNum):\n",
    "        sumlist=list()\n",
    "        for j in range(numrows):\n",
    "#             print 't,j',t,j\n",
    "            if t in NotBranched: \n",
    "                indj=NotBranched.index(t)\n",
    "#                 print 'indj',indj\n",
    "                indjrange=range(indj*ConstNum,(indj+1)*ConstNum)\n",
    "#                 print 'indjrange',indjrange\n",
    "                if j in indjrange:\n",
    "#                     print 'dd[j,t]+dd[j,t+VarNum]',j,'ll',dd[j,t]+dd[j,t+VarNum]\n",
    "                    sumlist.append(dd[j,t]+dd[j,t+VarNum])\n",
    "                    dd[j,t+VarNum]=0\n",
    "                else:\n",
    "                    sumlist.append(dd[j,t])\n",
    "            else:\n",
    "                sumlist.append(dd[j,t])\n",
    "        sumarray.append(sumlist)\n",
    "#     print 'sumarray',sumarray\n",
    "#     print 'newDD',dd\n",
    "  \n",
    "#     print 'notbranched',NotBranched\n",
    "    lenNotbranched=len(NotBranched)\n",
    "   \n",
    "    \n",
    "    for t in range(lenNotbranched):  \n",
    "        for i in range (VarNum):\n",
    "            sumlist=list()\n",
    "            if t>0:\n",
    "                for p in range(t):\n",
    "                    for j in range (ConstNum):\n",
    "                        sumlist.append(0) \n",
    "                        \n",
    "            for j in range(ConstNum):\n",
    "                sumlist.append(dd[t*ConstNum+j,i+VarNum])\n",
    "            if i in NotBranched and i > NotBranched[t]:\n",
    "                indx=NotBranched.index(i)\n",
    "                indy=NotBranched.index(NotBranched[t])\n",
    "                \n",
    "                for x in range(indx-indy-1):\n",
    "                    for j in range (ConstNum):\n",
    "                        sumlist.append(0) \n",
    "                for j in range(ConstNum):\n",
    "                    sumlist.append(dd[(indx)*ConstNum+j,NotBranched[t]+VarNum])\n",
    "                    dd[(indx)*ConstNum+j,NotBranched[t]+VarNum]=0\n",
    "#                 sumarray.append([t+indx,indy])\n",
    "                if t<lenNotbranched-2 :\n",
    "                    for p in range(lenNotbranched-indx-1):\n",
    "                        for j in range (ConstNum):\n",
    "                            sumlist.append(0)\n",
    "            else:\n",
    "                if t<lenNotbranched-1 :\n",
    "#                     print 'lenNotbranched',lenNotbranched\n",
    "                    for p in range(lenNotbranched-t-1):\n",
    "                            for j in range (ConstNum):\n",
    "                                sumlist.append(0) \n",
    "#             print 't,i',t,',',i\n",
    "#             print 'sumlist p2',sumlist\n",
    "#             print 'lensumlist p2',len(sumlist)\n",
    "            sumarray.append(sumlist)\n",
    "#     print 'part2' ,sumarray  \n",
    "    \n",
    "    rows=[]\n",
    "    for j in range(numrows):\n",
    "        my_row.append(1)\n",
    "    rows.append([range(numrows),my_row])  \n",
    "    def populatebyrow(SecProb):\n",
    "        SecProb.objective.set_sense(SecProb.objective.sense.maximize)\n",
    "        SecProb.variables.add(obj = my_obj,lb=my_lb, names = my_colnames)\n",
    "        \n",
    "        for i in range (len(sumarray)):\n",
    "            if all(k == 0 for k in sumarray[i])!=True:\n",
    "#                 print 'i',i\n",
    "                sumline=[]\n",
    "                sumline.append([range(len(sumarray[i])),sumarray[i]])\n",
    "#                 print 'sumline',sumline\n",
    "                SecProb.linear_constraints.add(lin_expr = sumline, senses =  \"E\",\n",
    "                                rhs = [0], names = [\"u\"+str(i)])\n",
    "        SecProb.linear_constraints.add(lin_expr = rows, senses = \"L\",\n",
    "                                             rhs = [1], names = [\"t0\"])\n",
    "    \n",
    "    my_SecProb = CPX.Cplex()\n",
    "    handle = populatebyrow(my_SecProb)\n",
    "    my_SecProb.solve()\n",
    "    my_SecProb.write(\"lpex2.lp\")\n",
    "    SecVariables    = my_SecProb.solution.get_values()\n",
    "    SecObjective=my_SecProb.solution.get_objective_value()\n",
    "#     print 'SecVariables,SecObjective,my_colnames',SecVariables, SecObjective,my_colnames\n",
    "    return SecVariables, SecObjective,my_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratintCutParameters ( m, n, my_rhs, my_coef, BranchedVariables,SecVariables): \n",
    "    BranchedLen=len(BranchedVariables)\n",
    "    unbranched=list()\n",
    "    for i in range (n):\n",
    "        if i not in (BranchedVariables):\n",
    "            unbranched.append(i)  \n",
    "    LeUnbranched=len(unbranched)                   \n",
    "#     NodeNum=n-len(unbranched)\n",
    "#     k=NodeNum-1 \n",
    "    lhs=(np.zeros((LeUnbranched*((2 * m) + (4 * n)),BranchedLen)))\n",
    "    rhs=(np.zeros((LeUnbranched*((2 * m) + (4 * n)),1)))\n",
    "\n",
    "    for i in range (LeUnbranched):   \n",
    "        for h in range (m):\n",
    "            for j in (BranchedVariables):\n",
    "                lhs[i*(2*m+4*n)+m+h][BranchedVariables.index(j)]=my_coef[h][j]*SecVariables[i*(2*m+4*n)+m+h]  \n",
    "                rhs[i*(2*m+4*n)+m+h]=my_rhs[h]*SecVariables[i*(2*m+4*n)+m+h]  \n",
    "            \n",
    "        for h in range (n):\n",
    "            for j in (BranchedVariables):\n",
    "                lhs[i*(2*m+4*n)+2*m+2*n+j][BranchedVariables.index(j)]=SecVariables[i*(2*m+4*n)+2*m+2*n+j]  \n",
    "                rhs[i*(2*m+4*n)+2*m+2*n+h]=SecVariables[i*(2*m+4*n)+2*m+2*n+h]  \n",
    "            \n",
    "#         for h in range (n):\n",
    "        for j in (BranchedVariables):\n",
    "            lhs[i*(2*m+4*n)+2*m+3*n+j][BranchedVariables.index(j)]=-1*SecVariables[i*(2*m+4*n)+2*m+3*n+j]  \n",
    "\n",
    "    #     print 'lefttt',lhs,'rightttt', rhs\n",
    "    LenLeft=len(lhs)\n",
    "    LenRight=len(rhs)\n",
    "    LenSec=len(SecVariables)\n",
    "#     print 'LenLeft',LenLeft\n",
    "#     print'LenRight',LenRight\n",
    "#     print 'LenSec',LenSec\n",
    "#     indicesLhs=[]\n",
    "#     for j in range (8):\n",
    "#         indicesLhs.append([i for i in range(LenLeft) if lhs[i][j]!=0]) \n",
    "#     print indicesLhs\n",
    "#     indicesRhs = [(i,rhs[i]) for i in range(LenRight) if rhs[i]>0]\n",
    "#     print 'indicesRhs',indicesRhs\n",
    "#     indiceSecVariables=[(i , SecVariables[i]) for i in range(LenSec) if SecVariables[i]!=0]\n",
    "#     ValueSecVariables=[SecVariables[i] for i in range(LenSec) if SecVariables[i]!=0]\n",
    "#     print 'positiveLeftHand',indicesLhs \n",
    "#     print 'indiceSecVariables',indiceSecVariables\n",
    "#     print 'ValueSecVariables', ValueSecVariables\n",
    "    FinalLhs=np.sum(lhs, axis=0)\n",
    "    FinalRhs=np.sum(rhs, axis=0)\n",
    "    print 'FinalLhs',FinalLhs, 'FinalRhs',FinalRhs\n",
    "    return FinalLhs,FinalRhs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCut(CPX_CB.UserCutCallback):\n",
    "\n",
    "    def __call__(self):\n",
    "         \n",
    "        self.times_called += 1\n",
    "        print  'self.times_called', self.times_called\n",
    "        branched=list()\n",
    "        values=list()\n",
    "        branchedNames=list()\n",
    "        global BranchedMatrix\n",
    "        senses= \"L\"\n",
    "#         print 'self.get_lower_bounds(s)',self.get_lower_bounds()\n",
    "#         print 'self.get_upper_bounds(s)',self.get_upper_bounds()\n",
    "#         print 'objective value', self.get_objective_value()\n",
    "#         print 'values', self.get_values()\n",
    "        print 'get_num_nodes', self.get_num_nodes()\n",
    "\n",
    "        lb=self.get_lower_bounds()\n",
    "        ub=self.get_upper_bounds()               \n",
    "        for j in range(len(lb)):\n",
    "            if lb[j]==ub[j]:\n",
    "                branched.append(j)\n",
    "                values.append(lb[j])\n",
    "                branchedNames.append(VarsName[j])\n",
    "                \n",
    "        print 'values',values\n",
    "        print 'branchedNames',branchedNames\n",
    "        print 'branched',branched\n",
    "\n",
    "#         if len(values)>0:  \n",
    "#             BranchedMatrix.append([branched,values])\n",
    "# #             BranchedValue.append(values)\n",
    "# #             print 'BranchedMatrix',BranchedMatrix\n",
    "\n",
    "#             if [BranchedMatrix[-1]]!=[BranchedMatrix[-2]] :\n",
    "#                 SecModelParameterOutput=SecModelParameter(values, self.m, self.n, self.my_rhs, self.my_coef,branched)\n",
    "#                 SecondModelOutput=SecondModel (SecModelParameterOutput[0],SecModelParameterOutput[1],SecModelParameterOutput[2])\n",
    "#                 print 'SecondModelOutput[1]',SecondModelOutput[1]\n",
    "#                 print 'SecondModelOutput[0]',SecondModelOutput[0]\n",
    "#                 if SecondModelOutput[1]>0.000001:\n",
    "#     #                 print 'bayad cut bezane'\n",
    "#                     output=GeneratintCutParameters (self.m, self.n, self.my_rhs, self.my_coef,branched, SecondModelOutput[0])\n",
    "#                     print 'output',output[0]\n",
    "#                     print 'output[1]',output[1]\n",
    "#                     lhs=[CPX.SparsePair(ind =branchedNames, val = output[0])]\n",
    "#                     print 'lhs',lhs[0]\n",
    "#                     self.add(cut=lhs[0],rhs=output[1][0],sense=senses)\n",
    "#                     print 'cut added'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Preprocessing_Linear                    0\n",
      "CPXPARAM_MIP_Interval                            1\n",
      "CPXPARAM_MIP_Strategy_Search                     1\n",
      "Found incumbent of value 0.000000 after 0.00 sec. (0.00 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 15 rows, 15 columns, and 225 nonzeros.\n",
      "Reduced MIP has 15 binaries, 0 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.02 sec. (0.06 ticks)\n",
      "Probing time = 0.00 sec. (0.01 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 15 rows, 15 columns, and 225 nonzeros.\n",
      "Reduced MIP has 15 binaries, 0 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.01 sec. (0.09 ticks)\n",
      "Probing time = 0.00 sec. (0.01 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.05 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.0000      678.0000              --- \n",
      "*     0+    0                          530.0000      678.0000            27.92%\n",
      "      0     0      608.5149     4      530.0000      608.5149        9   14.81%\n",
      "self.times_called 1\n",
      "get_num_nodes 0\n",
      "values [1.0]\n",
      "branchedNames ['x13']\n",
      "branched [13]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 392 columns.\n",
      "Reduced LP has 120 rows, 868 columns, and 10737 nonzeros.\n",
      "Presolve time = 0.02 sec. (1.17 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =           103.775495\n",
      "Iteration:    62   Scaled dual infeas =             9.019207\n",
      "Iteration:   124   Scaled dual infeas =             0.562417\n",
      "Iteration:   186   Scaled dual infeas =             0.176057\n",
      "Iteration:   245   Dual objective     =             0.005766\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     0      583.7757     7      530.0000      Cuts: 12       13   10.15%\n",
      "self.times_called 2\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 242 columns.\n",
      "Reduced LP has 111 rows, 748 columns, and 8073 nonzeros.\n",
      "Presolve time = 0.02 sec. (0.88 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =            51.333332\n",
      "Iteration:    62   Scaled dual infeas =             0.200659\n",
      "Perturbation started.\n",
      "Iteration:   102   Scaled dual infeas =             0.200667\n",
      "Iteration:   164   Scaled dual infeas =             0.051494\n",
      "Iteration:   188   Dual objective     =             0.020833\n",
      "Iteration:   249   Dual objective     =             0.010293\n",
      "Iteration:   311   Dual objective     =             0.000000\n",
      "Removing perturbation.\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      0     0      580.5541     9      530.0000      Cuts: 15       20    9.54%\n",
      "\n",
      "Repeating presolve.\n",
      "Tried aggregator 1 time.\n",
      "MIP Presolve eliminated 2 rows and 4 columns.\n",
      "MIP Presolve modified 20 coefficients.\n",
      "Reduced MIP has 13 rows, 11 columns, and 143 nonzeros.\n",
      "Reduced MIP has 11 binaries, 0 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.02 sec. (0.08 ticks)\n",
      "Probing time = 0.00 sec. (0.01 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 13 rows, 11 columns, and 143 nonzeros.\n",
      "Reduced MIP has 11 binaries, 0 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.00 sec. (0.06 ticks)\n",
      "Represolve time = 0.03 sec. (0.22 ticks)\n",
      "Probing time = 0.00 sec. (0.01 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.07 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                          530.0000      580.5541             9.54%\n",
      "      0     0      580.5541     9      530.0000      580.5541       32    9.54%\n",
      "self.times_called 3\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      580.0567     9      530.0000      Cuts: 15       40    9.44%\n",
      "self.times_called 4\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      579.7873     8      530.0000       Cuts: 8       44    9.39%\n",
      "self.times_called 5\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      575.4553     7      530.0000       Cuts: 6       50    8.58%\n",
      "self.times_called 6\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      574.5720     8      530.0000       Cuts: 4       54    8.41%\n",
      "self.times_called 7\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      573.3933     8      530.0000       Cuts: 4       58    8.19%\n",
      "self.times_called 8\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      572.8000     8      530.0000       Cuts: 8       61    8.08%\n",
      "self.times_called 9\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      572.5981     8      530.0000       Cuts: 3       65    8.04%\n",
      "self.times_called 10\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      572.4046    10      530.0000       Cuts: 2       68    8.00%\n",
      "self.times_called 11\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      572.3750    10      530.0000       Cuts: 2       70    8.00%\n",
      "self.times_called 12\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      571.8517    10      530.0000   ZeroHalf: 3       74    7.90%\n",
      "self.times_called 13\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      571.0073     9      530.0000       Cuts: 6       79    7.74%\n",
      "self.times_called 14\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      570.3630     9      530.0000       Cuts: 3       83    7.62%\n",
      "self.times_called 15\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      569.8391     9      530.0000       Cuts: 6       89    7.52%\n",
      "self.times_called 16\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      569.6091     9      530.0000   ZeroHalf: 2       92    7.47%\n",
      "self.times_called 17\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      569.3742     6      530.0000   ZeroHalf: 2       94    7.43%\n",
      "self.times_called 18\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      569.1345    10      530.0000       Cuts: 5      100    7.38%\n",
      "self.times_called 19\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      568.9914    10      530.0000   ZeroHalf: 2      103    7.36%\n",
      "self.times_called 20\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     0      568.9831    10      530.0000       Cuts: 3      105    7.36%\n",
      "self.times_called 21\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "self.times_called 22\n",
      "get_num_nodes 0\n",
      "values [1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x2', 'x5', 'x12', 'x13']\n",
      "branched [2, 5, 12, 13]\n",
      "      0     2      568.9831    10      530.0000      568.9692      105    7.35%                        0             0\n",
      "Elapsed time = 0.80 sec. (5.26 ticks, tree = 0.01 MB, solutions = 2)\n",
      "self.times_called 23\n",
      "get_num_nodes 1\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x12', 'x13']\n",
      "branched [0, 2, 5, 12, 13]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 200 columns.\n",
      "Reduced LP has 106 rows, 700 columns, and 7229 nonzeros.\n",
      "Presolve time = 0.02 sec. (0.79 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =           219.678552\n",
      "Iteration:    62   Scaled dual infeas =             0.779461\n",
      "Iteration:   124   Scaled dual infeas =             0.328724\n",
      "Iteration:   162   Dual objective     =             0.030644\n",
      "Iteration:   223   Dual objective     =             0.000000\n",
      "Perturbation started.\n",
      "Iteration:   264   Dual objective     =             0.000000\n",
      "Removing perturbation.\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "self.times_called 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_num_nodes 1\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x12', 'x13']\n",
      "branched [0, 2, 5, 12, 13]\n",
      "      1     3      568.8548     9      530.0000      568.9691      108    7.35%              x0 U      1      0      1\n",
      "self.times_called 25\n",
      "get_num_nodes 2\n",
      "values [-0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x12', 'x13']\n",
      "branched [0, 2, 5, 12, 13]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 200 columns.\n",
      "Reduced LP has 106 rows, 700 columns, and 7229 nonzeros.\n",
      "Presolve time = 0.02 sec. (0.79 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =            51.333332\n",
      "Iteration:    62   Scaled dual infeas =             0.200659\n",
      "Perturbation started.\n",
      "Iteration:   102   Scaled dual infeas =             0.200667\n",
      "Iteration:   159   Dual objective     =             0.026678\n",
      "Iteration:   220   Dual objective     =             0.007795\n",
      "Removing perturbation.\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "self.times_called 26\n",
      "get_num_nodes 2\n",
      "values [-0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x12', 'x13']\n",
      "branched [0, 2, 5, 12, 13]\n",
      "      2     4      568.5878     8      530.0000      568.5854      112    7.28%              x0 D      2      0      1\n",
      "self.times_called 27\n",
      "get_num_nodes 3\n",
      "values [-0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 5, 8, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 128 columns.\n",
      "Reduced LP has 93 rows, 592 columns, and 5607 nonzeros.\n",
      "Presolve time = 0.00 sec. (0.62 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =           279.658617\n",
      "Iteration:    62   Scaled dual infeas =             0.585748\n",
      "Iteration:   124   Scaled dual infeas =             0.087157\n",
      "Iteration:   142   Dual objective     =             0.057859\n",
      "Iteration:   203   Dual objective     =             0.022577\n",
      "Iteration:   265   Dual objective     =             0.000012\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2078109459929376, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0049783623513951734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13026750390893907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013118184845311675, 0.0, 0.0, 2.1777515265131928e-05, 0.0011192980245794857, 0.0003665297639824194, 0.0, 0.0, 0.0, 0.0, 0.000939997990318507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017833706500647757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11576156849818364, 0.0, 0.0, 0.0, 0.0, 0.022076866580995648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11595662406877823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08502275205388707, 0.0, 0.2524689231919662, 0.04078726398003821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0032760610935548256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.times_called 28\n",
      "get_num_nodes 3\n",
      "values [-0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 5, 8, 12, 13, 14]\n",
      "      3     5      568.5070     7      530.0000      568.5854      114    7.28%             x14 U      3      2      2\n",
      "self.times_called 29\n",
      "get_num_nodes 4\n",
      "values [-0.0, -0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x1', 'x2', 'x5', 'x6', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 1, 2, 5, 6, 8, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 72 columns.\n",
      "Reduced LP has 76 rows, 468 columns, and 4074 nonzeros.\n",
      "Presolve time = 0.02 sec. (0.45 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "self.times_called 30\n",
      "get_num_nodes 4\n",
      "values [-0.0, -0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x1', 'x2', 'x5', 'x6', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 1, 2, 5, 6, 8, 12, 13, 14]\n",
      "      4     6      568.4643     3      530.0000      568.5854      115    7.28%              x6 U      4      3      3\n",
      "self.times_called 31\n",
      "get_num_nodes 5\n",
      "values [-0.0, -0.0, 1.0, 1.0, 1.0, 1.0, -0.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x1', 'x2', 'x5', 'x6', 'x8', 'x10', 'x12', 'x13', 'x14']\n",
      "branched [0, 1, 2, 5, 6, 8, 10, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 50 columns.\n",
      "Reduced LP has 66 rows, 400 columns, and 3340 nonzeros.\n",
      "Presolve time = 0.00 sec. (0.37 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "self.times_called 32\n",
      "get_num_nodes 5\n",
      "values [-0.0, -0.0, 1.0, 1.0, 1.0, 1.0, -0.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x1', 'x2', 'x5', 'x6', 'x8', 'x10', 'x12', 'x13', 'x14']\n",
      "branched [0, 1, 2, 5, 6, 8, 10, 12, 13, 14]\n",
      "      5     7      559.8094     3      530.0000      568.5854      121    7.28%             x10 D      5      4      4\n",
      "      6     6    infeasible            530.0000      568.5854      121    7.28%             x10 U      6      4      4\n",
      "self.times_called 33\n",
      "get_num_nodes 7\n",
      "values [-0.0, -0.0, 1.0, -0.0, 1.0, 1.0, 1.0, -0.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x1', 'x2', 'x4', 'x5', 'x6', 'x8', 'x10', 'x12', 'x13', 'x14']\n",
      "branched [0, 1, 2, 4, 5, 6, 8, 10, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 32 columns.\n",
      "Reduced LP has 55 rows, 328 columns, and 2628 nonzeros.\n",
      "Presolve time = 0.00 sec. (0.29 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "self.times_called 34\n",
      "get_num_nodes 7\n",
      "values [-0.0, -0.0, 1.0, -0.0, 1.0, 1.0, 1.0, -0.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x1', 'x2', 'x4', 'x5', 'x6', 'x8', 'x10', 'x12', 'x13', 'x14']\n",
      "branched [0, 1, 2, 4, 5, 6, 8, 10, 12, 13, 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7     6      547.3963     3      530.0000      568.5854      123    7.28%              x4 D      7      5      5\n",
      "      8     5    infeasible            530.0000      568.5854      123    7.28%              x4 U      8      5      5\n",
      "      9     4    infeasible            530.0000      568.5854      123    7.28%              x9 D      9      7      6\n",
      "self.times_called 35\n",
      "get_num_nodes 10\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 5, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 162 columns.\n",
      "Reduced LP has 100 rows, 648 columns, and 6407 nonzeros.\n",
      "Presolve time = 0.02 sec. (0.70 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =          1345.313233\n",
      "Iteration:    62   Scaled dual infeas =             0.384384\n",
      "Iteration:   124   Scaled dual infeas =             0.359126\n",
      "Perturbation started.\n",
      "Iteration:   153   Scaled dual infeas =             0.359333\n",
      "Iteration:   215   Scaled dual infeas =             0.069137\n",
      "Iteration:   239   Dual objective     =             0.019138\n",
      "Iteration:   300   Dual objective     =             0.001989\n",
      "Iteration:   362   Dual objective     =             0.000444\n",
      "Iteration:   424   Dual objective     =             0.000228\n",
      "Iteration:   486   Dual objective     =             0.000060\n",
      "Removing perturbation.\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "self.times_called 36\n",
      "get_num_nodes 10\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 5, 12, 13, 14]\n",
      "self.times_called 37\n",
      "get_num_nodes 10\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 5, 12, 13, 14]\n",
      "     10     5      563.8430     3      530.0000      565.5708      134    6.71%             x14 N     10      1      2\n",
      "Elapsed time = 1.81 sec. (5.51 ticks, tree = 0.01 MB, solutions = 2)\n",
      "self.times_called 38\n",
      "get_num_nodes 11\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x4', 'x5', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 4, 5, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 128 columns.\n",
      "Reduced LP has 93 rows, 592 columns, and 5607 nonzeros.\n",
      "Presolve time = 0.01 sec. (0.62 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =           673.315204\n",
      "Iteration:    62   Scaled dual infeas =             0.591826\n",
      "Iteration:   124   Scaled dual infeas =             0.233256\n",
      "Iteration:   184   Dual objective     =             0.014572\n",
      "Iteration:   245   Dual objective     =             0.000000\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00014862052122709002, 0.0010418696382348473, 0.0005860950204827275, 0.0010563435144039586, 0.0, 0.00025205299190295084, 0.0, 0.0003792151461782751, 0.0007923509822273055, 0.0, 0.0, 0.0, 0.0, 0.0003563088070582511, 0.0, 0.08014881115111162, 0.0, 0.0, 0.0, 0.1182602707040143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13802395379698645, 0.0, 0.16419472375457117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08984438419685611, 0.0, 0.0, 0.08096639273089884, 0.0, 0.12527469453588366, 0.0, 0.0, 0.0, 0.19867391250796249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1250362580715887e-17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "self.times_called 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_num_nodes 11\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x4', 'x5', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 4, 5, 12, 13, 14]\n",
      "     11     4  -1.00000e+75     5      530.0000      565.5708      144    6.71%              x4 U     11     10      3\n",
      "self.times_called 40\n",
      "get_num_nodes 12\n",
      "values [1.0, 1.0, -0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x4', 'x5', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 4, 5, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 128 columns.\n",
      "Reduced LP has 93 rows, 592 columns, and 5607 nonzeros.\n",
      "Presolve time = 0.00 sec. (0.62 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =          1222.354962\n",
      "Iteration:    62   Scaled dual infeas =            27.476359\n",
      "Iteration:   124   Scaled dual infeas =             0.444865\n",
      "Iteration:   186   Scaled dual infeas =             0.282130\n",
      "Iteration:   229   Dual objective     =             0.016246\n",
      "Iteration:   290   Dual objective     =             0.002146\n",
      "Iteration:   352   Dual objective     =             0.000833\n",
      "Iteration:   414   Dual objective     =             0.000459\n",
      "SecondModelOutput[1] 0.000446705022221\n",
      "SecondModelOutput[0] [0.0, 8.169817476334936e-05, 0.0, 6.990158632427844e-05, 0.0, 0.0, 0.0, 0.0002476517893592093, 0.0, 0.0, 3.512678770837873e-05, 0.0, 0.0, 0.00014179059112262186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020582271990596704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006125264400977002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0359270904950468, 0.0036096597707956585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015717234600948118, 0.0, 0.0, 0.017545213385495466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035639073648001666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.953277385273863e-05, 0.0, 0.0, 0.0, 0.0001122864065379491, 0.0, 0.0, 0.0, 0.0, 0.0, 3.051827587587287e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0026794418225129612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002166100745843582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02381707391078212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011456221022668822, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003566588287415959, 0.0142712998865242, 0.0, 0.0, 0.0, 0.0, 0.0015008165686502457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.974891949723441e-05, 4.110117023950856e-05, 0.0, 1.6946272559834135e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.2926120650275e-06, 0.0, 0.0034850215581583273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0028698396356340453, 0.0, 0.0063302760750412294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0034750583741111844, 0.0, 0.0, 0.00021709634609799408, 0.0, 0.0, 0.003282968317980837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00017092475260747073, 0.0, 0.0, 0.02403086838379415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000209538128263197, 0.0, 0.0, 0.0, 0.0, 1.3416976000254142e-05, 0.0, 0.0, 0.0, 0.0, 4.7307775823837356e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.09841451614306e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002676335649224896, 0.0, 0.015625513178908423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005974760409814522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0095998708914866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014202544879884232, 0.0, 0.02452663292673914, 0.0, 0.0, 0.0, 0.0, 0.0024021793071928223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003018492447097505, 0.0, 0.0, 0.0, 0.0001758722182652017, 0.0, 0.0, 0.00043437456488189697, 0.0, 0.0, 0.0, 0.0, 0.00124757272883449, 0.0, 0.0007536553834853986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0038790619843348823, 0.03245752592351292, 0.06722192155328616, 0.0, 0.0, 0.0, 0.0, 0.05035943211927268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017810707399709788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044939153832450575, 0.0, 0.0, 0.0, 0.02604474883465689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.387180610415604e-05, 0.0, 0.0, 0.00018540580778459426, 0.0, 0.0, 0.00011005995096315636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036572087705997856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02425642942679405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03877298214919534, 0.0, 0.0, 0.0, 0.043397731788514395, 0.010285751454079128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012537340618139641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022087920611229876, 0.0, 0.0, 0.009091975092536259, 0.013715357906976663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04280242959061911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035289696755491325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019755897374403496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005181131252769519, 0.0, 0.004458027554820046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.137977574651487e-05, 0.00042076596109728176, 0.0002214283687210896, 0.0, 0.0, 0.0, 4.280095958928662e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020234444404799958, 0.0, 0.0, 0.014068660217855335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031622677776546974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03129903969595903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01662479602069812, 0.0, 0.0, 0.0, 0.0, 0.039528811362569936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024298781107806568, 0.0, 0.0432312925452139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "FinalLhs [ 0.07106371  0.03543188 -0.08240484  0.0226778   0.08902732  0.04897856\n",
      "  0.21794155] FinalRhs [0.4846741]\n",
      "output [ 0.07106371  0.03543188 -0.08240484  0.0226778   0.08902732  0.04897856\n",
      "  0.21794155]\n",
      "output[1] [0.4846741]\n",
      "lhs SparsePair(ind = ['x0', 'x2', 'x4', 'x5', 'x12', 'x13', 'x14'], val = array([ 0.07106371,  0.03543188, -0.08240484,  0.0226778 ,  0.08902732,\n",
      "        0.04897856,  0.21794155]))\n",
      "cut added\n",
      "     12     3    infeasible            530.0000      565.5708      148    6.71%              x4 N     12     10      3\n",
      "self.times_called 41\n",
      "get_num_nodes 13\n",
      "values [-0.0, 1.0, 1.0, -0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x6', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 5, 6, 8, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 98 columns.\n",
      "Reduced LP has 85 rows, 532 columns, and 4830 nonzeros.\n",
      "Presolve time = 0.02 sec. (0.53 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =           686.000000\n",
      "Iteration:    62   Scaled dual infeas =            11.214433\n",
      "Iteration:   124   Dual objective     =             0.260803\n",
      "Iteration:   185   Dual objective     =             0.053324\n",
      "Iteration:   247   Dual objective     =             0.014388\n",
      "Iteration:   309   Dual objective     =             0.008843\n",
      "SecondModelOutput[1] 0.00876529305077\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00013132397908140498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7620485761223418e-05, 0.0, 0.0, 0.0001300992367975531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017125531847284832, 0.0, 0.02469333294265225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022753657227555776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0034732901013726355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01649727856348444, 0.0, 0.0268876726453388, 0.0, 0.0, 0.0068710017514869255, 0.0, 0.0016676644046345326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.679854375335959e-05, 0.0, 1.4110416693981514e-05, 0.0, 0.0, 0.0, 4.612408166705025e-05, 3.5821056361703995e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7386879294854382e-05, 0.0, 0.0, 0.004544537099925903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015344234450788682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0029404635699802313, 0.0, 0.0, 0.003295306813618577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013269471695856049, 0.0009306002131152563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004000791548191243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5471454146760766e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2795249916500174e-05, 0.0, 0.0, 0.0, 0.0, 4.671836525573504e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00014073091321467179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009694272488156, 0.011296196627008268, 0.0, 0.011841329166346583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011504529637609343, 0.0, 0.0, 0.008658817231152709, 0.0, 0.0, 0.0, 0.0010110262958823372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0033809554231969074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00011171879604571366, 0.0003274798125449013, 7.2253992297385e-05, 0.0001231391085235904, 9.919455529549196e-05, 0.00011105521056144766, 0.0, 0.00019189177802467292, 0.0, 6.985809381643388e-05, 0.00021196989190019254, 7.308996610238019e-05, 0.0, 0.0, 0.00022302699499370882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00015378123990950402, 0.0, 0.0, 0.0, 0.008724599756261152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00811380628283092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001896224259323064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001896224259323064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00833143162779685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0007765633147959134, 0.0, 0.0004893038407288905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4143304666914365e-05, 0.0, 0.0, 0.00012608470842026033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0009763444381144704, 0.0, 0.0, 0.0, 0.0, 0.0002730013844079895, 0.0, 0.0, 0.0, 0.050231024329779994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16755011554669755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11337527046017269, 0.0, 0.0, 0.09847155708033752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01833996562702421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020772105528592898, 0.0904853940070881, 0.048547709056999386, 0.0, 0.0, 0.0, 0.0, 0.07725966927271477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.010920434198885e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.952531235224729e-05, 0.0, 0.0, 2.9958557207674573e-05, 0.0, 0.0, 0.0, 0.005602198983324617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005924161209352545, 0.0, 0.0, 0.0, 0.0008302862820681485, 0.010339958566388134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002352006054901662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008959650599925352, 0.0, 0.0, 0.0066125869679095894, 0.0, 0.03326993756733738, 0.0, 0.0, 0.0, 0.0, 0.0005093889552680455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinalLhs [-0.05664075  0.05386759  0.0005448  -0.18886784  0.06002418  0.11554406\n",
      "  0.00260272  0.13374998] FinalRhs [0.35756803]\n",
      "output [-0.05664075  0.05386759  0.0005448  -0.18886784  0.06002418  0.11554406\n",
      "  0.00260272  0.13374998]\n",
      "output[1] [0.35756803]\n",
      "lhs SparsePair(ind = ['x0', 'x2', 'x5', 'x6', 'x8', 'x12', 'x13', 'x14'], val = array([-0.05664075,  0.05386759,  0.0005448 , -0.18886784,  0.06002418,\n",
      "        0.11554406,  0.00260272,  0.13374998]))\n",
      "cut added\n",
      "     13     2    infeasible            530.0000      549.0327      154    3.59%              x6 N     13      3      3\n",
      "     14     1    infeasible            530.0000      549.0327      154    3.59%             x14 D     14      2      2\n",
      "self.times_called 42\n",
      "get_num_nodes 15\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 5, 8, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 128 columns.\n",
      "Reduced LP has 93 rows, 592 columns, and 5607 nonzeros.\n",
      "Presolve time = 0.00 sec. (0.62 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =           558.174410\n",
      "Iteration:    62   Scaled dual infeas =             6.356980\n",
      "Iteration:   124   Scaled dual infeas =             2.225965\n",
      "Iteration:   156   Dual objective     =             0.237525\n",
      "Iteration:   217   Dual objective     =             0.049631\n",
      "Iteration:   279   Dual objective     =             0.003090\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "self.times_called 43\n",
      "get_num_nodes 15\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 5, 8, 12, 13, 14]\n",
      "self.times_called 44\n",
      "get_num_nodes 15\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0]\n",
      "branchedNames ['x0', 'x2', 'x5', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 5, 8, 12, 13, 14]\n",
      "     15     2      546.6718     4      530.0000      545.4467      164    2.91%             x14 N     15      1      2\n",
      "self.times_called 45\n",
      "get_num_nodes 16\n",
      "values [1.0, 1.0, -0.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0]\n",
      "branchedNames ['x0', 'x2', 'x4', 'x5', 'x6', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 4, 5, 6, 8, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 72 columns.\n",
      "Reduced LP has 76 rows, 468 columns, and 4074 nonzeros.\n",
      "Presolve time = 0.02 sec. (0.45 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =           222.000000\n",
      "Iteration:    62   Scaled dual infeas =             2.637295\n",
      "Iteration:   117   Dual objective     =             0.127188\n",
      "Iteration:   178   Dual objective     =             0.012986\n",
      "Iteration:   240   Dual objective     =            -0.000000\n",
      "Perturbation started.\n",
      "Iteration:   270   Dual objective     =            -0.000000\n",
      "Removing perturbation.\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "self.times_called 46\n",
      "get_num_nodes 16\n",
      "values [1.0, 1.0, -0.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0]\n",
      "branchedNames ['x0', 'x2', 'x4', 'x5', 'x6', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 4, 5, 6, 8, 12, 13, 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16     3      544.9317     4      530.0000      544.9316      166    2.82%              x4 D     16     15      3\n",
      "     17     2    infeasible            530.0000      544.9316      166    2.82%              x3 D     17     16      4\n",
      "self.times_called 47\n",
      "get_num_nodes 18\n",
      "values [1.0, 1.0, 1.0, -0.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0]\n",
      "branchedNames ['x0', 'x2', 'x3', 'x4', 'x5', 'x6', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 3, 4, 5, 6, 8, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 50 columns.\n",
      "Reduced LP has 66 rows, 400 columns, and 3340 nonzeros.\n",
      "Presolve time = 0.00 sec. (0.37 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =           155.000000\n",
      "Iteration:    62   Scaled dual infeas =             2.770661\n",
      "Iteration:    89   Dual objective     =             0.095572\n",
      "Iteration:   150   Dual objective     =             0.000797\n",
      "Iteration:   212   Dual objective     =             0.000328\n",
      "SecondModelOutput[1] -1.8269695271e-18\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04653914139468063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00010831998820181482, 0.0005282417806564893, 0.0, 0.0, 1.704841215769471e-05, 0.0, 0.0, 0.0015707297664050634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11058934459844219, 0.0, 0.0, 0.024847248319187647, 0.0, 0.0, 0.0, 0.0, 0.05152509148917437, 0.0, 0.0, 0.0, 0.20392035437009504, 0.05256737470787906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11385017976181702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008148603757180477, 0.0, 0.0, 0.062266784783330566, 0.0, 0.0, 0.08022508330098181, 0.09014921557621547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15314723799359464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "self.times_called 48\n",
      "get_num_nodes 18\n",
      "values [1.0, 1.0, 1.0, -0.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0]\n",
      "branchedNames ['x0', 'x2', 'x3', 'x4', 'x5', 'x6', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 3, 4, 5, 6, 8, 12, 13, 14]\n",
      "     18     3      544.7529     3      530.0000      544.0408      168    2.65%              x3 U     18     16      4\n",
      "     19     2    infeasible            530.0000      544.0408      168    2.65%             x10 U     19     18      5\n",
      "     20     1    infeasible            530.0000      536.4211      168    1.21%             x10 D     20     18      5\n",
      "Elapsed time = 2.73 sec. (5.77 ticks, tree = 0.01 MB, solutions = 2)\n",
      "self.times_called 49\n",
      "get_num_nodes 21\n",
      "values [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0]\n",
      "branchedNames ['x0', 'x2', 'x4', 'x5', 'x6', 'x8', 'x12', 'x13', 'x14']\n",
      "branched [0, 2, 4, 5, 6, 8, 12, 13, 14]\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 72 columns.\n",
      "Reduced LP has 76 rows, 468 columns, and 4074 nonzeros.\n",
      "Presolve time = 0.00 sec. (0.45 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Scaled dual infeas =            12.000000\n",
      "Iteration:    62   Scaled dual infeas =             0.204720\n",
      "Iteration:   100   Dual objective     =             0.019226\n",
      "Iteration:   161   Dual objective     =             0.001417\n",
      "Iteration:   223   Dual objective     =             0.000633\n",
      "Removing shift (1).\n",
      "SecondModelOutput[1] 0.0\n",
      "SecondModelOutput[0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "     21     0        cutoff            530.0000      530.0000      172    0.00%              x4 U     21     15      3\n",
      "\n",
      "Cover cuts applied:  2\n",
      "Flow cuts applied:  1\n",
      "Mixed integer rounding cuts applied:  2\n",
      "Zero-half cuts applied:  8\n",
      "Lift and project cuts applied:  1\n",
      "User cuts applied:  2\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.81 sec. (5.26 ticks)\n",
      "Sequential b&c:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Real time             =    2.05 sec. (0.58 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    2.86 sec. (5.84 ticks)\n",
      "MIP_optimal\n",
      "Objective value =  530.0\n",
      "\n",
      "Column 0: Value =                 1\n",
      "Column 1: Value =                 1\n",
      "Column 2: Value =                 1\n",
      "Column 5: Value =                 1\n",
      "Column 6: Value =                 1\n",
      "Column 7: Value =                 1\n",
      "Column 8: Value =                 1\n",
      "Column 9: Value =                 1\n",
      "Column 11: Value =                 1\n",
      "Column 12: Value =                 1\n",
      "Column 13: Value =                 1\n",
      "Branch callback was called  49 times\n"
     ]
    }
   ],
   "source": [
    "def admipex3(c):\n",
    "    \n",
    "    c.parameters.preprocessing.presolve = 0\n",
    "\n",
    "    c.parameters.preprocessing.reduce = 0\n",
    "\n",
    "    c.parameters.preprocessing.linear.set(0)\n",
    "\n",
    "    c.parameters.preprocessing.numpass = 0\n",
    "\n",
    "    c.parameters.mip.strategy.presolvenode = -1\n",
    "\n",
    "    c.parameters.preprocessing.linear = 0\n",
    "    \n",
    "def CutCplex(c):\n",
    "    c.parameters.mip.cuts.disjunctive.set(-1)\n",
    "    c.parameters.mip.cuts.bqp.set(-1)\n",
    "    c.parameters.mip.cuts.cliques.set(-1)\n",
    "    c.parameters.mip.cuts.covers.set(-1)\n",
    "    c.parameters.mip.cuts.flowcovers.set(-1)\n",
    "    c.parameters.mip.cuts.gomory.set(-1)\n",
    "    c.parameters.mip.cuts.gubcovers.set(-1)\n",
    "    c.parameters.mip.cuts.implied.set(-1)\n",
    "    c.parameters.mip.cuts.liftproj.set(-1)\n",
    "    c.parameters.mip.cuts.localimplied.set(-1)\n",
    "    c.parameters.mip.cuts.mcfcut.set(-1)\n",
    "    c.parameters.mip.cuts.mircut.set(-1)\n",
    "    c.parameters.mip.cuts.zerohalfcut.set(-1)\n",
    "    c.parameters.mip.cuts.pathcut.set(-1)\n",
    "    \n",
    "c = CPX.Cplex('NewExample.lp')\n",
    "m=c.linear_constraints.get_num()\n",
    "n=c.variables.get_num()\n",
    "my_rhs=[]\n",
    "my_coef=[]\n",
    "for i in range(m):\n",
    "    my_row=[]\n",
    "    for j in range(n):\n",
    "        my_row.append(c.linear_constraints.get_coefficients(i,j))\n",
    "    my_coef.append(my_row)\n",
    "\n",
    "for i in range (m):\n",
    "    my_rhs.append(c.linear_constraints.get_rhs(i))\n",
    "\n",
    "admipex3(c)\n",
    "VarsName=c.variables.get_names()\n",
    "c.set_log_stream(sys.stdout)\n",
    "c.set_results_stream(sys.stdout)\n",
    "\n",
    "cutinst=c.register_callback(MyCut)\n",
    "cutinst.times_called = 0\n",
    "cutinst.m=m\n",
    "cutinst.n=n\n",
    "cutinst.my_rhs=my_rhs\n",
    "cutinst.my_coef=my_coef\n",
    "cutinst.VarsName=VarsName\n",
    "BranchedMatrix=[[[-1], [-0.0]]]\n",
    "c.parameters.mip.interval.set(1)\n",
    "c.parameters.preprocessing.linear=0\n",
    "c.parameters.mip.strategy.search.set(c.parameters.mip.strategy.search.values.traditional)\n",
    "c.solve()\n",
    "\n",
    "c.write(\"lpex1.lp\")\n",
    "solution = c.solution\n",
    "\n",
    "# the following line prints the corresponding string\n",
    "print solution.status[solution.get_status()]\n",
    "print \"Objective value = \" , solution.get_objective_value()\n",
    "print\n",
    "x = solution.get_values(0, c.variables.get_num()-1)\n",
    "for j in range(c.variables.get_num()):\n",
    "    if fabs(x[j]) > 1.0e-10:\n",
    "        print \"Column %d: Value = %17.10g\" % (j, x[j])\n",
    "\n",
    "print \"Branch callback was called \", cutinst.times_called, \"times\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
